\documentclass[conference]{IEEEtran}
\usepackage{stmaryrd}
\usepackage{amsfonts}
% If the IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it: e.g.,
% \documentclass[conference]{../sty/IEEEtran}

\usepackage{graphicx,times,amsmath,multi row} % Add all your packages here

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

\IEEEoverridecommandlockouts    % to create the author's affliation portion
                % using \thanks

\textwidth 178mm    % <------ These are the adjustments we made 10/18/2005
\textheight 239mm   % You may or may not need to adjust these numbes again
\oddsidemargin -7mm
\evensidemargin -7mm
\topmargin -6mm
\columnsep 5mm

% -------- The above  is from IEEE Sample.tex
%\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
%\usepackage{epstopdf}
%\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
%\usepackage{amsmath,amsthm}
\usepackage{times}
\usepackage{color}
%\usepackage[pagewise]{lineno}

%\newcommand{\spacedouble}{\renewcommand{\baselinestretch}{0.95}\Huge\normalsize}
%\newcommand{\spacesingle}{\renewcommand{\baselinestretch}{1.0}\Huge\normalsize}
\newcommand{\cA}{{\cal A}}
\newcommand{\cD}{{\cal D}}
\newcommand{\cL}{{\cal L}}
\newcommand{\cP}{{\cal P}}
\newcommand{\cR}{{\cal R}}
\newcommand{\cS}{{\cal S}}
\newcommand{\cX}{{\cal X}}
\newcommand{\cY}{{\cal Y}}
\newcommand{\cZ}{{\cal Z}}
\def\a{\mathbf a}
\def\b{\mathbf b}
\def\d{\mathbf d}
\def\e{\mathbf e}
\def\f{\mathbf f}
\def\m{\mathbf m}
\def\o{\mathbf o}
\def\p{\mathbf p}
\def\q{\mathbf q}
\def\r{\mathbf r}
\def\s{\mathbf s}
\def\t{\mathbf t}
\def\u{\mathbf u}
\def\v{\mathbf v}
\def\w{\mathbf w}
\def\x{\mathbf x}
\def\y{\mathbf y}
\def\z{\mathbf z}

\def\imagetop#1{\vtop{\null\hbox{#1}}}

\newcommand{\marginlabel}[1]{}

%\renewcommand{\thesection}{\Roman{section}}
\newtheorem{algorithm}{Algorithm}
\newtheorem{definition}{Definition}
\newtheorem{challenge}{Challenge}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{problem}{Problem}
\newtheorem{procedure}{Procedure}
\newtheorem{property}{Property}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}

% --------- the following is from IEEE Sample.tex ----

\begin{document}


% paper title: Must keep \ \\ \LARGE\bf in it to leave enough margin.
\title{\ \\ \LARGE\bf Novelty Detection in Developmental Networks: \\
Acetylcholine and Norepinenephrine\thanks{Jordan Fish, Lisa Ossian, and Juyang Weng is with the Department of Computer Science and Engineering, Cognitive Science Program, and Neuroscience Program, 
Michigan State University, East Lansing, MI, 48824 USA. (email: \{fishjord,ossianli,weng\}@cse.msu.edu).}}

\author{Jordan Fish, Lisa Ossian, and Juyang Weng}

% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership
% use only for invited papers
%\specialpapernotice{(Invited Paper)}

% make the title area
\maketitle

\begin{abstract}
The receiver operating characteristic (ROC) 
curve has been widely applied to classifiers to show how the threshold value for acceptance changes the true positive rate and 
the false positive rate of the detection jointly.  However, it is largely unknown how a biological brain autonomously selects a confidence value for each detection case.  In the reported work, we investigated this issue based on the class of Developmental Networks (DNs) which have a power of
abstraction similar to symbolic finite automata (FA)
but all the DN's internal representations are emergent
(i.e., numeric and non-symbolic).  Our theory is based on two types of neurotransmitters: Acetylcholine (Ach) and Norepinenephrine (NE).  Inspired by studies that
proposed Ach and NE represent uncertainty and 
unpredited uncertainty, respectively, we model how a DN uses 
Ach and NE to allow neurons to collectively decide acceptance or rejection by estimated 
novelty based on past experience, instead of using a threshold value.   This is a neural network, 
distributed, incremental, automatic version of ROC. 
\end{abstract}

% no key words

\section{Introduction}

Two types of problems are well studied in pattern recognition: classification and detection.   
In a classification problem, all possible inputs belong to one of $n$ classes.   The task is to determine 
which class each input most likely belongs to.   In a detection problem, the simplest case is a two-set
problem: acceptable (admissible) set and rejection set.   The task is to determine whether each input is
admissible or not.   Face detection is a widely studied task, where the admissible set consists of faces and
the rejection set consists of all the non-faces.   

In the work here, we address both problems using a unified neural network framework --- Developmental Networks (DN) \cite{WengNAI12}.    The environment teaches the DN to have two types of actions, 
rejection or acceptance.  For accepted case, the network produce the most likely class.    For $n$ admissible
classes, the DN has $n+1$ neurons in the motor (action) area $Z$ which is used for output and input.
If the teacher teaches the DN, the desired output for the current input is fed to the motor area $Z$ as 
supervised input to the DN.  A high novelty detected indicates that the input should be rejected. 

Inspired by neuromodulation in the brain wherein different types of
neurotransmitters are used to represent different types of statistics.
We model the effects of two types of neural transmitters, Acetylcholine (Ach) and Norepinenephrine (NE).

By definition \cite{WengRepRev12}, an {\em emergent representation} develops autonomously from system's  interactions with the {\em external} (outside the skull) world and
the {\em internal world} (inside the skull) via the brain's sensors and
effectors without using the handcrafted (or gene-specified) content or the handcrafted 
boundaries of internal modules defined by extra-body concepts.
 
Weng \cite{WengWhy11} established on a theoretical basis that although a DN is an emergent model,
it can abstract as well as any symbolic model since it can learn any large and complex finite
automaton (FA) incrementally from the observation of the input-output activities of the FA's operation.
Furthermore, DN learning is immediate and error free for all sequences that the FA has demonstrated.
Furthermore, the DN can generalize to all other sequences that have not been learned by the DN or experienced by
the FA, but are state-equivalent in the sense of FA.   This is because each FA maps all possible 
input sequences into $n$ states, where $n$ is the number of states in the FA.  Typically, most of
such sequences have not been observed by the FA, showing the high power of state-based generalization. 
  
In the following two sections we briefly discuss these two types of models, symbolic and emergent. 

\subsection{Symbolic models}
Given a task, a human designer in Artificial Intelligence (AI) \cite{Soar87,Hawkins09} or Cognitive Science \cite{Anderson93,Tenenbaum06} handcrafts a Symbolic Network (SN), using handpicked task-specific 
concepts as symbols.   The ``common denominator'' network underlying many such SNs is a Finite Automaton (FA) whose probabilistic extensions include  
 Hidden Markov Models (HMM), the Partially Observable Markov Decision Processes (POMDP)
and Bayesian Nets (also called belief nets, semantic nets, and graphical models). Markou \& Singh \cite{Markou03s} gave a review of novelty detection using statistical approaches. 

\subsection{Emergent networks}

An emergent representation emerges autonomously from a system's interactions with the {\em external} world and
the {\em internal world} via its sensors and
its effectors without using the handcrafted (or gene-specified) content or the handcrafted 
boundaries for concepts about the extra-body environments.

Feed-forward \cite{Serre07,Rogers08} and recurrent \cite{Hinton06,Yamashita08} networks, use 
images (numeric patterns) as representations.    Recurrent networks can run continuously to take into account temporal information.  The network representations are emergent in the sense that the internal
representations, such as network connection patterns, multiple synaptic weights, and neuronal responses, emerge automatically 
through the interactions between the learner system and its environment.   
However, it is unclear how a recurrent network can model a brain.  

Markou \& Singh \cite{Markou03} gave a review of novelty detection using neural networks --- mainly 
emergent models. 

\subsection{DN architecture}

A basic DN has three areas, the sensory area $X$, the internal (brain) area $Y$ and the motor area $Z$.  The internal neurons in $Y$ have bi-directional connection with both $X$ and $Z$.  

In principle, the $X$ area can model any sensory modality (e.g., vision, audition, and touch). 
The motor area $Z$ serves both input and output.  When the environment supervises $Z$, $Z$ is the input
to the network.  Otherwise, $Z$ gives an output vector to drive effectors (muscles) which act on the real world. 
The order of areas from low to high is: $X, Y, Z$.   For example, 
$X$ provides bottom-up input to $Y$, but $Z$ gives top-down input to $Y$.  

\subsection{DN algorithm}
A DN has its area $Y$ as a ``bridge'' for its two banks, $X$ and $Z$.
If $Y$ is meant for modeling the entire brain, $X$ consists of all receptors and $Z$ consists of all muscle 
neurons.   $Y$ potentially can also model any Brodmann area in the brain.   According to 
many studies in detailed review
by Felleman \& Van Essen \cite{FellemanVanEssen91}, each area $Y$ connects in bi-directionally with many other
areas as its two extensive banks.  

The most basic function of an area $Y$ seems to be prediction --- predict the signals in its two vast banks $X$ and $Y$ through
space and time.   The prediction applies when part of a bank is not supervised. 
The prediction also makes its bank less noisy if the bank can generate its own signals (e.g., $X$).    

Although being convenient for studying infinitesimal changes (see, e.g., \cite{Izhikevich07}), a continuous time model  seems not very effective to explain network abstraction.   In the following, $\delta$ is consider a unit, so we denote the time by integers $\delta=0, 1, 2, ...$.  

A DN operates as follows.  
Input areas: $X$ and $Z$.  Output areas: $X$ and $Z$.   The dimension and representation of $X$ and $Y$ areas are hand designed based on the sensors and effectors of the robotic agent or biologically regulated by the genome. $Y$ is skull-closed inside the brain, not directly accessible  by the external world after the birth.     
\begin{enumerate}
\item At time $\delta=0$, for each area $A$ in $\{X, Y, Z\}$, initialize 
its adaptive part $N=(V, G)$ and the response vector $\r$, where $V$ contains all the synaptic weight vectors and $G$ stores all the neuronal ages, in biological neurons.
\item At time $\delta=1, 2, ... $, for each $A$ in $\{X, Y, Z\}$ repeat: 
\begin{enumerate}
\item Every area $A$ computes its area function $f$, described below, 
\begin{equation}
(\r', N') = f(\b, \t, \r, N)
\end{equation}
where $\r'$ is the new response vector of $A$, $\b$ is the bottom-up input to $A$ and $\t$ is the top-down input to $A$.  
\item For every area $A$ in $\{X, Y, Z\}$, $A$ replaces: $N\leftarrow N'$ and $\r \leftarrow \r'$.
\end{enumerate}
\end{enumerate}

$Y$ is the large hidden area of DN.  If $X$ is a sensory area, $\x \in X$ is always supervised. The $\z \in Z$ is supervised only when the teacher chooses to.   Otherwise, $\z$ gives (predicts) effector output.  

\subsection{Unified DN area function}
Each area $A$ has a weight vector $\v= (\v_b, \v_t)$ where $\v_b$ is the set of weights associated with bottom-up inputs and $\v_t$ is the set of weights associated with the top-down inputs for $A$.  Its pre-response value is:
\begin{equation}
\label{EQ:pre-response}
r (\v_b, \b, \v_t, \t)  
= \dot{\v} \cdot \dot{\p}
\end{equation}
where
$\dot{\v}$ is the unit vector of the normalized synaptic vector 
$\v= (\dot{\v}_b, \dot{\v}_t)$, and $\dot{\p}$ is the unit vector of the normalized input vector 
$\p= (\dot{\b}, \dot{\t})$.    The inner product measures the degree of match between these two directions 
$\dot{\v}$ and $\dot{\p}$, because $r (\v_b, \b, \v_t, \t) = \cos(\theta) $ where $\theta$ is the angle between 
two unit vectors $\dot{\v}$ and $\dot{\p}$.
This enables a match between two vectors of different magnitudes (e.g., a weight vector from an object viewed indoor to match the same object when it is viewed  outdoor). 
The pre-response value ranges in $[-1, 1]$.

This pre-response is inspired by how each neuron takes many lines of input from bottom-up and top-down sources.  It generalizes across contrast (i.e., the length of vectors).   It uses inner-product $\dot{\v} \cdot \dot{\p}$ to
generalize across many different vectors that are otherwise simply different as with symbols in an FA.  The normalization of the bottom-up part and the top-down part separately is for both the bottom-up source and top-down source
to be taken into account, regardless the dimension and magnitude of each source. 

To simulate lateral inhibitions (winner-take-all) within each area $A$, the $k$ neurons with the highest response fire and the rest are suppressed (response set to 0).  Considering $k=1$, the winner neuron $j$ is identified by:
\begin{equation}
j = \mbox{arg}\max_{1\le i \le c}  r (\v_{bi}, \b, \v_{ti}, \t) .
\label{EQ:jmax}
\end{equation}
The area dynamically scale top-k winners so that the top-k respond with values in $(0, 1]$.   
For $k=1$, only the single winner fires with response value 
$y_j=1$ (a pike) and all other neurons in $A$ do not fire.  The response value $y_j$ approximates the 
probability for $\dot{\p} $ to fall into the Voronoi region of its $\dot{\v}_j$ where the ``nearness'' 
is $r (\v_b, \b, \v_t, \t)$.

For more information related to Development Networks see \cite{WengIJCNN11,Weng3ThmRpt11}.

\subsection{Novelty: Acetylcholine and Norepinenephrine}
Neurotransmitters are chemicals that allow the transmission of signals across synapses from one neuron to another. In the brain, several classes of neurotransmitters are used to connect one neuron to multiple neurons; this is called neural modulation. Neural modulation is needed in the brain to indicate certain properties about
sensory and motor signals \cite{WengNAI12}. Brains without neural modulation simply
respond to these signals and are not aware of the underlying properties that exist between them. This can be observed in children with ADHD who have trouble paying attention to detail. Neurons that are capable of neural modulation, such as acetylcholine and norepinephrine, are called neural modulators.

Yu \& Dayan \cite{Yu05} proposed that acetylcholine indicates expected uncertainty, while norepinephrine indicates unexpected uncertainty. Expected uncertainty is the known unreliability that occurs in a familiar environment, one in which a network has had a lot of experience. Unexpected uncertainty, or novelty, is the strongly unexpected observations that occur in an unfamiliar environment. Novelty is important to detect in neural networks, since it is impossible to train a neural network on all possible input.

Markou \& Singh \cite{Markou03} identified the main criterion for evaluating neural-network-based approaches to novelty detection as the maximization of true positives, or correctly-identified, novel input patterns, along with the minimization of false positives, or incorrectly-identified, novel input patterns. There are a number of neural-network-based approaches to novelty detection that perform well by this criterion. For instance, Ryan et al. \cite{Ryan98} threshold the output of a neural network and detect novelty from low confidence, and Singh \& Markou \cite{Singh04} close known class boundaries, identify novel samples with their rejection filter, cluster these samples, and compare the clusters with known class distributions to determine whether they are outliers. However, both of these methods were implemented on multi-layer feed forward neural networks, or multi-layer perceptron. There was not a approach to novelty detection on a developmental network.

In the work presented in this paper, we extend the developmental network proposed by Weng \cite{WengNAI12} to be a neuromorphic system using acetylcholine and norepinephrine to detect novelty in input patterns. The developmental network presented performs facial recognition.  

\subsection{Modeling the Ach and NE Systems}
Weng \cite{WengNAI12} introduced the theory for the neuromorphic, or emergent neuromodulation, system of acetylcholine (Ach) and norepinephrine (NE). Each neuron conducts synaptic maintenance, maintaining its synapses based on expected uncertainty, modeled by Ach, and unexpected uncertainty, modeled by NE. The goal of synaptic maintenance is to maximize the removal of irrelevant post-synaptic neurons, while minimizing the removal of relevant post-synaptic neurons, which in effect isolates the important information from the input.

The input to each neuron is in the form $\mathbf{p}=(p_1,p_2,\dots,p_d)$ and its synaptic weight vector is represented by $\mathbf{v}=(v_1,v_2,\dots,v_d)$.

The synapse of a firing top-k neuron $y$ contains information from the mean of the pre-synaptic activities, or input patterns, $x_i$. This can be written as:
\begin{align}v_i=E[yp_i\; | \;\text{the neuron fires}] \end{align}
which is calculated using the amnesic average \cite{WengNAI12}. Expected uncertainty is measured for each synapse $i$ by calculating the deviation of the match between $v_i$ and $p_i$:
\begin{align}\sigma_i=E[|v_i-p_i|\;|\;\text{the neuron fires}]\end{align}

Ach needs to be calculated incrementally and stably. The measure of unexpected uncertainty in equation (2) must be initialized with constant values and must wait until all synaptic weights have sufficient estimates of $w_i$. Letting $n$ represent the firing age of the neuron, for each synapse $n \le n_0$, the synapse is initialized to the standard deviation of the uniform distribution in $[-\delta,\delta]$. This standard deviation needs to be plastic continuously, so a constant asymptotic learning rate is used. Letting $\sigma_i(n)$ represent $\sigma_i$ at firing age $n$, synapse deviation is computed incrementally (as Ach) as follows:
\begin{align}\sigma_i(n)=\left\{
\begin{array}{l l}
\delta/\sqrt{12} &\text{if $n \le n_0$}\\
w_1(n)\sigma_i(n)+w_2(n)|v_i-p_i| & \text{otherwise}
\end{array}\right.\end{align}
where $w_1(n)$ is the retention rate and $w_2(n)$ is the learning rate, given by:
\begin{align}w_2(n)=\frac{1+\mu(n)}{n},w_1(n)=1-w_2(n). \nonumber 
\end{align}
To ensure sufficient estimates of synaptic weights through the first $n_0$ updates, set $n_0=20$. 

A neuron conducts synaptic maintenance based on the following equation for the expected goodness of match
as average Ach:
\begin{align}\bar{\sigma}(n)=\frac{1}{d}\sum_{i=1}^d\sigma_i(n)\end{align}
$\bar{\sigma}(n)$ represents the expected synaptic deviation among all of a neuron's synapses.

If $\sigma_i(n)$ is large, synapse $i$ should be retracted; however, setting a hard threshold may cause synapses to be retracted and extracted more than once. So a smooth synaptogenic factor $f(r)$ is defined, which is dependent on the relative synaptic deviation $r(n)$ as NE:
\begin{align}r_i(n)=\frac{\sigma_i(n)}{\bar{\sigma}(n)}\end{align}
\begin{align}
f(r)=\left\{
\begin{array}{l l}
1 & \text{if $r < \beta_s$} \\
(\beta_b-r)/(\beta_b-\beta_s) & \text{if $\beta_s \le r \le \beta_b$} \\
0 & \text{otherwise}
\end{array}\right.\end{align}
where $\beta_s=1.0$ and $\beta_b=1.5$. If all synapses match perfectly, then for all $i$, $r_i(n)=1$ and $f(r_i(n))=1$; in this case, no synapses should be cut. In the case where all synapses do not match perfectly, synapses with $r_i(n) < \beta_s$ are fully operational, synapses with $\beta_s < r_i(n) < \beta_b$ are partially cut, and synapses with $\beta_b < r_i(n)$ are completely cut. Weng \cite{WengNAI12} hypothesized that synapses with $\beta_b < r_i(n)$ indicate novelty. For input patterns that produce $\beta_b < r_i(n)$ in a synapse, the developmental network needs to reject.

\section{Experimental Results}

The development network was implemented using Python 2.7 using NumPy 1.61 for vector math functions.  The deviation from the expected input was computed for each neuron at each synapse in each layer during supervised training.  The expected deviation was only updated when a neuron fired and the network was not allowed to reject input during the training phase.

When testing, for each input pattern the top k firing neurons estimated the deviation from the expected value for each synapse.  Each dimension in the input whose $r$-value that was below a threshold $R$ was counted.  If the ratio of dimensions that had unexpected novelty to the total number of dimensions was larger than a threshold $\theta$ the neuron firing was suppressed.  This suppression was done in the Y layer only.

For the first training epoch the input images were ordered such that the network was presented one view of each person before seeing a new view of the same person, this was done to speed up training convergence.  For subsequent training epochs the images were presented to the network in a random order.

For evaluating the network the admissible and not admissible set were created based on the idea that during any given day a person encounters many more faces of people they do not know (faces that the network should reject) than faces they do know.  Additionally the people encountered can be very well known (many training views) or only a casual acquaintance (few training views).  Admissible and not admissible images were selected from a set of a total of 1825 views of 188 people.  For the admissible set 14 people totaling 187 views were selected and used to train the network. The number of views for each individual ranging from 6 to 53. Fig. \~ref{fig:training} shows the first view of the 14 people used to train the network and the number of views for each individual; person one is in the top left corner through person 14 in the lower right. The testing set consisted of 1638 views over all 188 people in the dataset.  Of these there were 295 views of the 14 people in the admissible set on and 1343 views of 174 people in the not admissible set.  

\begin{figure}
\center
\fontsize{8}{12}\selectfont
\includegraphics[width=3in]{figs/training_faces}
\begin{tabular}{c} \\[3ex] \end{tabular}
\begin{tabular}{|c|c|}
  \hline
  Person & Number of views\\
  \hline
  1 & 6\\
  2 & 7\\
  3 & 6\\
  4 & 22\\
  5 & 9\\
  6 & 16\\
  7 & 7\\
  8 & 22\\
  9 & 7\\
  10 & 7\\
  11 & 8\\
  12 & 7\\
  13 & 10\\
  14 & 53\\
  \hline
\end{tabular}
\caption{First view of the 14 people in the admissible set and the number of views for each person.  Person one is in the top left corner through person 14 in the lower right.}
\label{fig:training}
\end{figure}

The development network was built using 25 neurons in the Y layer and trained over 50 epochs of the training images.  For each epoch the optimal value for $R$ and $\theta$ were searched for using the grid search technique.  The search was performed over a subset of the input parameter space $R=[0.05-0.90]$ and $\theta=[0.05-0.90]$.  The sensitivity and specificity for each pair of values $R$ and $\theta$ were computed and plotted in a Receiver Operating Characteristics Curve, five representative epochs of which can be seen in \ref{fig:roc}. The network rapidly stabilized and achieved the best accuracy, $95.8\%$ after the third training epoch.  After the sixth training epoch the network achieved it's maximum sensitivity and specificity of $96.6\%$ and $92.5\%$ respectively with $R=.4$ and $\theta=.35$ and had an accuracy of $91.9\%$.  Beyond this point the sensitivity and specificity drop as the network began to over fit the training data.  

\begin{figure}
\center
\fontsize{8}{12}\selectfont
\includegraphics[width=2.75in]{figs/roc}
\caption{Receiver operating characteristic (ROC) curve for training epochs 1, 6, 9 and 26.  This figure shows how the sensitivity and specificity increase with the number of training epochs (curves shifting closer to the upper right hand corner) then fall off after the network begins over fitting.}
\label{fig:roc}
\end{figure}

The sixth training epoch, where the highest sensitivity and specificity were achieved, was analyzed further.  First the pre-synaptic weights for the $Y$ and $Z$ layer were visualized.  Fig. \~ref{fig:y\_weights} shows the pre-synaptic weights for the Y layer; these images are essentially averages of the input images that each neuron responds to.  Then the expected variation for each Y neuron, $\sigma$ was plotted in \ref{fig:y_sigmas}.  Each pixel represented the amount of variation the specific $Y$ neuron expects from the $X$ layer neuron.  Darker pixels represent lower expected variation while lighter pixels represent inputs with higher expected variation.  Of note is the first Y neuron, which is trained to respond to the background image that is presented before each classification task.  The image is a picture of the background each person had their picture taken against and the same image was presented each time which is why the expected variation is 0, an all black image.  For the Z layer the pre-synaptic weights for each of plotted in \ref{fig:z_weights} 5 per line. The lighter a square is the higher the weight for that Y neuron.  The firing ages for each of the Y and Z neurons were graphed in \${fig:ages} which showed that three neurons (neurons 2, 11, and 22) were under-utilized, responding to only a single view from the admissible set.  This is also shown in \ref{fig:y_sigmas} as the black squares, representing no expected variation in the input for those neurons.

\begin{figure}
\center
\includegraphics[width=3in]{figs/epoch_5_0_xy}
\caption{Visualization of pre-synaptic weights for the 25 Y layer neurons after the sixth training epoch, the first image corresponds to the Y neuron that responds to the background image presented to the network before every classification face.}
\label{fig:y_weights}
\end{figure}

\begin{figure}
\center
\includegraphics[width=3in]{figs/epoch_5_0_sigmas}
\caption{Visualization of the expected variance for each of the 25 neurons in the Y layer after the sixth training epoch.  The darker areas show inputs from the X layer where little variation is expected while the white areas show inputs that are expected to have larger variation.  Four neurons: 1, 2, 10, 22 (all black images) had no expected variation.}
\label{fig:y_sigmas}
\end{figure}

\begin{figure}
\center
\includegraphics[width=3in]{figs/epoch_5_0_yz}
\caption{Visualization of pre-synaptic weights for Z layer neurons after the sixth training epoch.  Each square represents a Z neuron.  The 25 pixels in each of the 25x25 squares represents the response weight for the corresponding Y neuron, the lighter the pixel the higher the weight.}
\label{fig:z_weights}
\end{figure}

\begin{figure}
\center
\fontsize{8}{12}\selectfont
\includegraphics[width=1.5in]{figs/epoch_5_y_ages}
\includegraphics[width=1.5in]{figs/epoch_5_z_ages}
\caption{Plot of Y (left) and Z (right) neuron firing ages after the sixth training epoch.  The first (left most) Y neuron and last (right most) Z neuron are the neurons trained to respond to the background image that is presented before every image, which is why the firing rate for those neurons are higher than the rest.}
\label{fig:ages}
\end{figure}

Finally for the sixth epoch the 126 errors the network made when using the parameters $R=.4$ and $\theta=.35$ were broken down by error type: false acceptance, false rejection, and incorrect classification. Of the 126 errors a large number were duplicates of the same error, incorrectly classifying multiple views of the same person in to the same category.  Consolidating the errors down to one person input person-incorrect classification pair there were 3 false acceptances, 7 false rejections, and 2 incorrect classifications as seen in \ref{fig:6_epoch_errors}.  The falsely accepted faces on visual inspect appear very similar to people in the training set.  The false rejections appear to be a combination of mismatched white-balancing and errors made due to different facial expressions.  The mistakes appear to be due to facial expressions and orientations different from the learned faces.  The incorrect classifications and false rejections due to facial expressions can be improved by increasing the number of neurons in the Y layer.

\begin{figure}
\center
\begin{tabular}{cc}
\fontsize{8}{12}\selectfont
a \imagetop{\includegraphics[width=1.4in]{figs/false_accept_combined}} &
\multirow{2}{*}{b \imagetop{\includegraphics[width=1.4in]{figs/false_reject_combined}}} \\
c \imagetop{\includegraphics[width=1.4in]{figs/mistakes_combined}} & \\[60ex]
\end{tabular}
\caption{a. The incorrectly accepted image (on the left) compared to the y neuron pre-synaptic weights for the Y neuron with the highest response to the input image. b. Input image (left) compared to the first input face for the falsely rejected images. c. The input image (left) and view of the person (right) the network labeled the two misclassified people as.}
\label{fig:6_epoch_errors}
\end{figure}

\section{Conclusion}
The DN has been extended to include the Acetylcholine system and the Norepinenephrine system. 
By learning not only the patterns that come from each class but the expected distribution of the patterns this neural network is able to detect novel input patterns. The experiments here used images that are properly scaled and centered.   The future work is to apply the Ach and NE systems to the more general setting where
objects can appear at any location in a clutter background, as the Where-What Network \cite{WengNAI12}, an embodiment 
of DN, has been tested with but without the novelty detection mechanisms reported here. 


\label{SE:bib}
\bibliographystyle{plain}
%\bibliographystyle{Science}
\bibliography{shoslifref}

\end{document}  
